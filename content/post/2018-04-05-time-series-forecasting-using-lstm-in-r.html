---
title: Time Series Forecasting using LSTM in R
author: Richard Wanjohi, Ph.D
date: '2018-04-05'
slug: time-series-forecasting-using-lstm-in-r
categories:
  - Deep Learning
tags:
  - Keras
  - R
  - Tensorflow
output:
  blogdown::html_page:
    toc: true
    #fig_width: 6
    #dev: "svg"
---


<div id="TOC">
<ul>
<li><a href="#brief-introduction">Brief Introduction</a></li>
<li><a href="#load-the-neccessary-libraries-the-dataset">Load the neccessary libraries &amp; the dataset</a></li>
<li><a href="#transform-data-to-stationary">Transform data to stationary</a></li>
<li><a href="#lagged-dataset">Lagged dataset</a></li>
<li><a href="#split-dataset-into-training-and-testing-sets">Split dataset into training and testing sets</a></li>
<li><a href="#normalize-the-data">Normalize the data</a></li>
<li><a href="#define-the-model">Define the model</a></li>
<li><a href="#compile-the-model">Compile the model</a></li>
</ul>
</div>

<p><code>still under construction</code></p>
<p>Mid 2017 R launched package <em>Keras</em>, a comprehensive library which runs on top of Tensorflow, with both CPU and GPU capabilities. I highlighted its implementation <a href="https://www.linkedin.com/pulse/finally-deep-learning-keras-tensorflow-r-richard-wanjohi-ph-d/">here</a>. In this blog I will demonstrate how we can implement time series forecasting using LSTM in R.</p>
<!--more-->
<hr />
<div id="brief-introduction" class="section level2">
<h2>Brief Introduction</h2>
<p>Time series involves data collected sequentially in time. I denote univariate data by $x_{t} \in \mathbb{R} $ where $t \in \mathcal{T} $ is the time indexing when the data was observed. The time $ t $ can be discrete in which case $\mathcal{T} = \mathbb{Z} $ or continuous with $\mathcal{T} = \mathbb{R} $. For simplicity of the analysis we will consider only discrete time series.</p>
<p>Long Short Term Memory (LSTM) networks are special kind of Recurrent Neural Network (RNN), that are capable of learning long-term dependencies. LSTM netowrk typically consists of memory blocks, referred to as cells, connected through layers. The information in the cells is cointained in cell state $ C_{t} $ and hidden state $ h_{t} $ and it is regulated by mechanisms, known as gates, through <em>sigmoid</em> and <em>tanh</em> activation functions.</p>
<p>The sigmoid function/layer outputs numbers between 0 and 1 with 0 indicating ‘Nothing goes through’ and 1 implying ‘Everything goes through’. LSTM, therefore, have the ability to, conditionally, add or delete information from the cell state.</p>
<p>The gates takes in, as input, the hidden states from previous time step $ h_{t-1} $ and the current input $ x_{t} $ and multiply them pointwise by weight matrices, $ W $, and bias $ b $ is added to the product.</p>
<p>Three main gates:</p>
<ol style="list-style-type: decimal">
<li>Forget gate:
<ul>
<li>This determine what information will be deleted from the cell state.</li>
<li>The output is a number between 0 and 1 with 0 meaning ‘delete all’ and 1 implying ‘remember all’</li>
</ul></li>
</ol>
<p><span class="math display">\[ f_{t} = \sigma \big(W_{f}[h_{t-1}, x_{t}] + b_{f} \big) \]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Input gate:
<ul>
<li>In this step, the <em>tahn</em> activation layer create a vector of potential canditate as follows:</li>
</ul>
<p><span class="math display">\[ \hat{C_{t}} = \tanh \big(W_{c}[h_{t-1}, x_{t}] + b_{c})  \]</span></p>
<ul>
<li>The sigmoid layer creates an update filter as follows:</li>
</ul>
<p><span class="math display">\[ U_{t} = \sigma \big(W_{u}[h_{t-1}, x_{t}] + b_{u} \big) \]</span></p>
<ul>
<li>Next, the old cell state $ C_{t-1} $ is updated as follows: <span class="math display">\[ C_{t} = f_{t} * C_{t-1} + U_{t} * \hat{C_{t}} \]</span></li>
</ul></li>
<li>Output gate:
<ul>
<li>In this step, the sigmoid layer filters the cell state that is going to output.</li>
</ul>
<p><span class="math display">\[ O_{t} = \sigma \big(W_{o}[h_{t-1}, x_{t}] + b_{o}) \]</span></p>
<ul>
<li>Then, the cell state $ C_{t} $ is passed thro tanh function to scale values to the range -1 to 1.</li>
<li>Finally, the scaled cell state is multiplied by the filtered output to obtain the hidden state $ h_{t} $ to be passed on to the next cell:</li>
</ul>
<p><span class="math display">\[ h_{t} = O_{t} * tanh(C_{t}) \]</span></p></li>
</ol>
</div>
<div id="load-the-neccessary-libraries-the-dataset" class="section level2">
<h2>Load the neccessary libraries &amp; the dataset</h2>
<pre class="r"><code># Load the necessary packages
library(keras)
library(tensorflow)</code></pre>
<p>Or install as follows:</p>
<pre class="r"><code>devtools::install_github(&quot;rstudio/keras&quot;)
# then install Tensorflow backend as follows:
library(keras)
install_keras()</code></pre>
<p>We will use the US long-term interest rates data, available <a href="http://stats.oecd.org/viewhtml.aspx?datasetcode=MEI_FIN&amp;lang=en">here</a> This is a monthly data from Jan 2007 to March 2018.</p>
<p><img src="/post/2018-04-05-time-series-forecasting-using-lstm-in-r_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>First five observations</p>
<pre><code>## [1] 4.76 4.72 4.56 4.69 4.75 5.10</code></pre>
</div>
<div id="transform-data-to-stationary" class="section level2">
<h2>Transform data to stationary</h2>
<p>This is done by getting the difference between two consecutive values in the series. This transformation, commonly known as differencing, removes components in the data that are time dependent. Furthermore, it is easier to model using the difference, rather than the raw values, and the resulting model has a higher predictive power.</p>
<pre class="r"><code># transform data to stationarity
diffed = diff(Series, differences = 1)
head(diffed)</code></pre>
<pre><code>## [1] -0.04 -0.16  0.13  0.06  0.35 -0.10</code></pre>
</div>
<div id="lagged-dataset" class="section level2">
<h2>Lagged dataset</h2>
<p>LSTM expects the data to be in a supervised learning mode. That is having a target variable Y and predictor, X. To achieve this, we transform the series by lagging the series and have the value at time $ (t-1) $ as the input and value at time $ t $ as the ouput, for a 1-step lagged dataset.</p>
<pre class="r"><code>supervised_transform &lt;- function(x, k= 1){
    
      lagged =  c(rep(NA, k), x[1:(length(x)-k)])
      DF = as.data.frame(cbind(lagged, x))
      colnames(DF) &lt;- c( paste0(&#39;x-&#39;, k), &#39;x&#39;)
      DF[is.na(DF)] &lt;- 0
      return(DF)
}
supervised = supervised_transform(diffed, 1)
head(supervised)</code></pre>
<pre><code>##     x-1     x
## 1  0.00 -0.04
## 2 -0.04 -0.16
## 3 -0.16  0.13
## 4  0.13  0.06
## 5  0.06  0.35
## 6  0.35 -0.10</code></pre>
</div>
<div id="split-dataset-into-training-and-testing-sets" class="section level2">
<h2>Split dataset into training and testing sets</h2>
<pre class="r"><code>## split into train and test sets

N = nrow(supervised)
n = round(N *0.7, digits = 0)
train = supervised[1:n, ]
test  = supervised[(n+1):N,  ]</code></pre>
</div>
<div id="normalize-the-data" class="section level2">
<h2>Normalize the data</h2>
<p>LSTM, like other neural network models, requires input data to be within the scale of activation function. The default function is sigmoid whose range is [-1, 1]</p>
<pre class="r"><code>## scale data
scale_data &lt;- function(train, test, feature_range = c(0, 1)) {
  x = train
  fr_min = feature_range[1]
  fr_max = feature_range[2]
  std_train = ((x - min(x) ) / (max(x) - min(x)  ))
  std_test  = ((test - min(x) ) / (max(x) - min(x)  ))
  
  scaled_train = std_train *(fr_max -fr_min) + fr_min
  scaled_test = std_test *(fr_max -fr_min) + fr_min
  
  return( list(scaled_train = as.vector(scaled_train), scaled_test = as.vector(scaled_test) ,scaler= c(min =min(x), max = max(x))) )
  
}


Scaled = scale_data(train, test, c(-1, 1))

y_train = Scaled$scaled_train[, 2]
x_train = Scaled$scaled_train[, 1]

y_test = Scaled$scaled_test[, 2]
x_test = Scaled$scaled_test[, 1]</code></pre>
<p>The following code will be required to revert the data to their original scale</p>
<pre class="r"><code>## inverse-transform
invert_scaling = function(scaled, scaler, feature_range = c(0, 1)){
  min = scaler[1]
  max = scaler[2]
  n = length(scaled)
  mins = feature_range[1]
  maxs = feature_range[2]
  inverted_dfs = numeric(n)
  
  for( i in 1:n){
    X = (scaled[i]- mins)/(maxs - mins)
    rawValues = X *(max - min) + min
    inverted_dfs[i] &lt;- rawValues
  }
  return(inverted_dfs)
}</code></pre>
</div>
<div id="define-the-model" class="section level2">
<h2>Define the model</h2>
<pre class="r"><code># Reshape the input
dim(x_train) &lt;- c(length(x_train), 1, 1)

# specify required arguements
X_shape2 = dim(x_train)[2]
X_shape3 = dim(x_train)[3]
batch_size = 1
units = 4

#=========================================================================================

model &lt;- keras_model_sequential() 
model%&gt;%
  layer_lstm(units, batch_input_shape = c(batch_size, X_shape2, X_shape3), stateful= TRUE)%&gt;%
  layer_dense(units = 1)</code></pre>
</div>
<div id="compile-the-model" class="section level2">
<h2>Compile the model</h2>
<pre class="r"><code>model %&gt;% compile(
  loss = &#39;mean_squared_error&#39;,
  optimizer = optimizer_adam( lr= 0.0001 , decay = 1e-6 ),  
  metrics = c(&#39;accuracy&#39;)
)</code></pre>
<p>Model summary</p>
<pre class="r"><code>summary(model)</code></pre>
<pre><code>## ___________________________________________________________________________
## Layer (type)                     Output Shape                  Param #     
## ===========================================================================
## lstm_1 (LSTM)                    (1, 4)                        96          
## ___________________________________________________________________________
## dense_1 (Dense)                  (1, 1)                        5           
## ===========================================================================
## Total params: 101
## Trainable params: 101
## Non-trainable params: 0
## ___________________________________________________________________________</code></pre>
<div id="fit-the-model" class="section level4">
<h4>Fit the model</h4>
<pre class="r"><code>Epochs = 50   
for(i in 1:Epochs ){
  model %&gt;% fit(x_train, y_train, epochs=1, batch_size=batch_size, verbose=1, shuffle=FALSE)
  model %&gt;% reset_states()
}


L = length(x_test)
scaler = Scaled$scaler
predictions = numeric(L)

for(i in 1:L){
     X = x_test[i]
     dim(X) = c(1,1,1)
     yhat = model %&gt;% predict(X, batch_size=batch_size)
     # invert scaling
     yhat = invert_scaling(yhat, scaler,  c(-1, 1))
     # invert differencing
     yhat  = yhat + Series[(n+i)]
     # store
     predictions[i] &lt;- yhat
}</code></pre>
<p>Plot the values</p>
<pre><code>## [1] 0.039</code></pre>
<p><img src="/post/2018-04-05-time-series-forecasting-using-lstm-in-r_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>Get the entire code in <a href="https://github.com/rwanjohi/Keras-in-R">my git repo</a></p>
</div>
</div>
