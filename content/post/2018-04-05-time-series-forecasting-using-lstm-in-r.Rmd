---
title: Time Series Forecasting using LSTM in R
author: Richard Wanjohi, Ph.D
date: '2018-04-05'
slug: time-series-forecasting-using-lstm-in-r
categories:
  - Deep Learning
tags:
  - Keras
  - R
  - Tensorflow
output:
  blogdown::html_page:
    toc: true
    #fig_width: 6
    #dev: "svg"
---

Under construction!!! 
the page `is good` but the `output` not soo good 

<!--more-->

***
## Brief Introduction

Time series involves data collected sequentially in time. I denote univariate data by $y_{t} \in \mathbb{R} $  where 
$t \\in \\mathcal{T} $  is the time indexing when the data was observed. The time  $ t $  can be discrete in which case $\mathcal{T} = \mathbb{Z} $ or continuous  with $\mathcal{T} = \mathbb{R} $. 

For simplicity of the analysis we will consider only discrete time series.

Long Short Term Memory networks are special kind of RNN (Recurrent Neural Network), that are capable of learning long-term dependencies. LSTM netowrk typically consists of memory blocks, referred to as cells, connected through layers.
The information in the cells is cointained in cell state $ C_{t} $ and hidden state $ h_{t} $ and its manipulated by mechanisms, known as gates, through *sigmoid* and *tanh* activation functions.

Cell states Ct, the lstm have ability to, conditionally, add or delete info from the cell state, a  process is regulated by structures known as gates.

The gates consist of sigmoid function/layer and outputs number between 0 and 1 with 0 meaning 'None' and 1 means 'All'

 
Three main gates:

1. Forget gate:
      + This determine what information will be deleted from the cell state. 
  
  $$ f_{t} = \sigma \big(W_{f}[h_{t-1}, x_{t}] + b_{f} \big) $$
  
2. Input gate:
       + this 
       
    $$ U_{t} = \sigma \big(W_{u}[h_{t-1}, x_{t}] + b_{u} \big) $$

3. 






```{r, warning=FALSE, message=FALSE}
# Load the necessary packages
library(keras)
library(tensorflow)

```
Or install as follows:
```{r, warning=FALSE, message=FALSE, eval=FALSE}
devtools::install_github("rstudio/keras")
# then install Tensorflow backend as follows:
library(keras)
install_keras()
```


## Load the dataset
We will use the US long-term interest rates data, available [here](http://stats.oecd.org/viewhtml.aspx?datasetcode=MEI_FIN&lang=en)
```{r, results= 'hide', include= FALSE}

df = read.table('C:/Users/Richard/Desktop/LTIR_US.csv', sep = ',', header = TRUE, na.strings = 'NULL')

Series = df$Value
L = length(Series)

```

First five observations
```{r, echo= FALSE}
head(Series)
```


## Differencing 

For stationarity 
```{r}
# transform data to stationarity
diffed = diff(Series, differences = 1)
head(diffed)
```



## Lagged dataset

Transform the series into supervised learning


```{r}
supervised_transform <- function(x, k= 1){
    
      lagged =  c(rep(NA, k), x[1:(length(x)-k)])
      DF = as.data.frame(cbind(lagged, x))
      colnames(DF) <- c( paste0('x-', k), 'x')
      DF[is.na(DF)] <- 0
      return(DF)
}
supervised = supervised_transform(diffed, 1)
head(supervised)
```


## Split dataset into training and testing sets

```{r}
## split into train and test sets

N = nrow(supervised)
n = round(N *0.7, digits = 0)
train = supervised[1:n, ]
test  = supervised[(n+1):N,  ]

```


## Normalize the data
LSTM, like other neural network models, requires input data to be within the scale of activation function. The default function is sigmoid whose range is [-1, 1]


```{r}


## scale data
scale_data <- function(train, test, feature_range = c(0, 1)) {
  x = train
  fr_min = feature_range[1]
  fr_max = feature_range[2]
  std_train = ((x - min(x) ) / (max(x) - min(x)  ))
  std_test  = ((test - min(x) ) / (max(x) - min(x)  ))
  
  scaled_train = std_train *(fr_max -fr_min) + fr_min
  scaled_test = std_test *(fr_max -fr_min) + fr_min
  
  return( list(scaled_train = as.vector(scaled_train), scaled_test = as.vector(scaled_test) ,scaler= c(min =min(x), max = max(x))) )
  
}


Scaled = scale_data(train, test, c(-1, 1))

y_train = Scaled$scaled_train[, 2]
x_train = Scaled$scaled_train[, 1]

y_test = Scaled$scaled_test[, 2]
x_test = Scaled$scaled_test[, 1]
```

The following code will be required to revert the data to their original scale

```{r}
## inverse-transform
invert_scaling = function(scaled, scaler, feature_range = c(0, 1)){
  min = scaler[1]
  max = scaler[2]
  n = length(scaled)
  mins = feature_range[1]
  maxs = feature_range[2]
  inverted_dfs = numeric(n)
  
  for( i in 1:n){
    X = (scaled[i]- mins)/(maxs - mins)
    rawValues = X *(max - min) + min
    inverted_dfs[i] <- rawValues
  }
  return(inverted_dfs)
}

```


## Define the model
```{r, results= 'hide'}
# Reshape the input
dim(x_train) <- c(length(x_train), 1, 1)

# specify required arguements
X_shape2 = dim(x_train)[2]
X_shape3 = dim(x_train)[3]
batch_size = 1
units = 4

#=========================================================================================

model <- keras_model_sequential() 
model%>%
  layer_lstm(units, batch_input_shape = c(batch_size, X_shape2, X_shape3), stateful= TRUE)%>%
  layer_dense(units = 1)
```

## Compile the model

``` {r}
model %>% compile(
  loss = 'mean_squared_error',
  optimizer = optimizer_adam( lr= 0.0001 , decay = 1e-6 ),  
  metrics = c('accuracy')
)

```

Model summary

```{r}
summary(model)
```

#### Fit the model

```{r, results= 'hide', eval= FALSE}
Epochs = 50   
for(i in 1:Epochs ){
  model %>% fit(x_train, y_train, epochs=1, batch_size=batch_size, verbose=1, shuffle=FALSE)
  model %>% reset_states()
}


L = length(x_test)
scaler = Scaled$scaler
predictions = numeric(L)

for(i in 1:L){
     X = x_test[i]
     dim(X) = c(1,1,1)
     yhat = model %>% predict(X, batch_size=batch_size)
     # invert scaling
     yhat = invert_scaling(yhat, scaler,  c(-1, 1))
     # invert differencing
     yhat  = yhat + Series[(n+i
     # store
     predictions[i] <- yhat
}


```

Get the entire code in [my git repo](https://github.com/rwanjohi/Keras-in-R)

